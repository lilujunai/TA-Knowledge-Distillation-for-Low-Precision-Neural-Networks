{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jesusnavarro/Desktop/cs282_proj\n"
     ]
    }
   ],
   "source": [
    "from resnet_quant import *\n",
    "from resnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model\n",
    "qparams = [4, 4, 'dorefa'] # [abit, qbit, quant_method] --- only dorefa has been implemented\n",
    "\n",
    "# resnet models are 8, 14, 16, 24\n",
    "\n",
    "# activation and weight quantization are computed slightly different.\n",
    "quant_resnet = get_quant_model('resnet8', qparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: first and last layer are not quantized \n",
    "# looking at layer ouptuts using hooks\n",
    "outputs=[]\n",
    "quant_resnet = get_quant_model('resnet8', qparams)\n",
    "\n",
    "\n",
    "def hook(module, input, output):\n",
    "    outputs.append(output)\n",
    "\n",
    "# Registering quantized act and \n",
    "for n, m in quant_resnet.named_modules():\n",
    "    if n == 'conv1': # first layer output\n",
    "        m.register_forward_hook(hook)\n",
    "    elif 'qfn' in n:\n",
    "        m.register_forward_hook(hook)\n",
    "    elif 'fc' in n:\n",
    "        m.register_forward_hook(hook)\n",
    "import torch\n",
    "# reset model or it will continue appending outputs \n",
    "image = torch.unsqueeze(torch.rand(size=(3, 32, 32)), dim=0)\n",
    "out = quant_resnet(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08691858 -0.13056552 -0.07414071 ... -0.32856515 -0.5100109\n",
      " -0.31090957]\n",
      "[0.         0.         0.         ... 0.6        0.         0.73333335]\n",
      "[-0.0940421  -0.03134737  0.03134739 ... -0.03134737 -0.03134737\n",
      "  0.03134739]\n",
      "[0.6        0.         0.4        ... 0.46666667 0.         0.2       ]\n",
      "[-0.03089878  0.03089881 -0.15449388 ...  0.03089881 -0.09269633\n",
      " -0.09269633]\n",
      "[0.         0.         0.         ... 1.         0.53333336 1.        ]\n",
      "[-0.01912601 -0.13388206 -0.01912601 ... -0.01912601  0.01912603\n",
      " -0.01912601]\n",
      "[0.         0.         0.46666667 ... 0.93333334 0.         0.        ]\n",
      "[ 0.02225179  0.02225179  0.11125886 ... -0.06675531  0.02225179\n",
      "  0.1557624 ]\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "[ 0.04640684  0.1082826   0.04640684 ...  0.07734472  0.04640684\n",
      " -0.01546894]\n",
      "[0.         0.         0.26666668 ... 0.         0.06666667 0.8666667 ]\n",
      "[ 0.01505579  0.04516736  0.07527892 ... -0.0752789  -0.04516734\n",
      " -0.01505578]\n",
      "[-0.08671793  0.18297285 -0.19683298  0.16536272 -0.30727726 -0.1950524\n",
      " -0.29528025  0.4667179  -0.10643439  0.01313841  0.31263784  0.01782516\n",
      " -0.16513713  0.09794978 -0.05964646  0.26092908 -0.12210678 -0.2472537\n",
      " -0.0357831  -0.26637352  0.00943197  0.2277826  -0.4478019  -0.01228225\n",
      "  0.12346648  0.11135715 -0.14721732 -0.11303873 -0.37008354  0.15620747\n",
      "  0.05191626  0.53728503  0.2768386  -0.08877824 -0.19267477  0.3321988\n",
      " -0.0053199   0.3665939   0.1386917  -0.2941875  -0.26368365 -0.05897401\n",
      "  0.3430804  -0.04940917  0.14153542  0.31787014  0.42343897  0.17135699\n",
      " -0.06481424 -0.21407013 -0.05603826 -0.09003343 -0.17275773  0.02452034\n",
      "  0.28418452  0.32471102  0.02745584 -0.32914168 -0.3653317   0.3920741\n",
      " -0.20500734 -0.03448029  0.20084262 -0.27729195 -0.12489603 -0.22804019\n",
      "  0.22173923  0.16904302 -0.06891249 -0.14115931 -0.07914953  0.06717013\n",
      "  0.03483588  0.19501323 -0.36756504 -0.26885897  0.14505811 -0.19697683\n",
      "  0.5396188  -0.20939048 -0.23765129 -0.25072396 -0.47658762 -0.43287447\n",
      "  0.19298318  0.25357628  0.32717624 -0.06437513 -0.32638654  0.26390037\n",
      " -0.3357768  -0.20092161  0.10675271 -0.26860258  0.23051102  0.58568203\n",
      "  0.09431086  0.3137732   0.00949699  0.01921892]\n"
     ]
    }
   ],
   "source": [
    "# look at some values at intermediate layer outputs\n",
    "# weights and acitvations are quantized but operations are still in full precision\n",
    "# with the final layer also full precision\n",
    "\n",
    "for output in outputs:\n",
    "    output = output.view(1, -1)\n",
    "    print(np.squeeze(output.data.numpy()[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# print outputs\n",
    "# simple loss function to look at gradients\n",
    "loss = torch.sum(out)\n",
    "print(out.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNet_Cifar' object has no attribute 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4b57bdcd4b0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resnet8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_qat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/envs/cs282_proj/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ResNet_Cifar' object has no attribute 'features'"
     ]
    }
   ],
   "source": [
    "resnet = get_model('resnet8')\n",
    "torch.quantization.prepare_qat(resnet, inplace=True)\n",
    "print(resnet.features[1].conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
