{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from resnet_quant import *\n",
    "from resnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model\n",
    "qparams = [4, 4, 'dorefa'] # [abit, qbit, quant_method] --- only dorefa has been implemented\n",
    "\n",
    "# resnet models are 8, 14, 16, 24\n",
    "\n",
    "# activation and weight quantization are computed slightly different.\n",
    "quant_resnet = get_quant_model('resnet8', qparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: first and last layer are not quantized \n",
    "# looking at layer ouptuts using hooks\n",
    "outputs=[]\n",
    "quant_resnet = get_quant_model('resnet8', qparams)\n",
    "\n",
    "\n",
    "def hook(module, input, output):\n",
    "    outputs.append(output)\n",
    "\n",
    "# Registering quantized act and \n",
    "for n, m in quant_resnet.named_modules():\n",
    "    if n == 'conv1': # first layer output\n",
    "        m.register_forward_hook(hook)\n",
    "    elif 'qfn' in n:\n",
    "        m.register_forward_hook(hook)\n",
    "    elif 'fc' in n:\n",
    "        m.register_forward_hook(hook)\n",
    "import torch\n",
    "# reset model or it will continue appending outputs \n",
    "image = torch.unsqueeze(torch.rand(size=(3, 32, 32)), dim=0)\n",
    "out = quant_resnet(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12953429  0.12341644  0.26982716 ...  0.07344282  0.09889573\n",
      " -0.02507184]\n",
      "[0.6666667 0.6       1.        ... 0.        0.        0.       ]\n",
      "[ 0.07930576  0.07930576 -0.13217624 ... -0.07930574  0.07930576\n",
      " -0.13217624]\n",
      "[0.  0.  0.  ... 0.2 1.  1. ]\n",
      "[-0.175937    0.1256693  -0.27647245 ... -0.07540157  0.1256693\n",
      "  0.07540159]\n",
      "[0.6666667 1.        0.        ... 0.        0.        0.       ]\n",
      "[-0.02174077 -0.06522232 -0.02174077 ...  0.15218543 -0.10870387\n",
      " -0.15218541]\n",
      "[0.         0.53333336 0.         ... 1.         0.6666667  1.        ]\n",
      "[-0.02142314  0.02142316 -0.06426942 ... -0.02142314 -0.02142314\n",
      "  0.06426943]\n",
      "[1.  0.4 1.  ... 1.  0.  0.8]\n",
      "[ 0.07327925  0.07327925  0.07327925 ... -0.04396754 -0.10259093\n",
      " -0.01465585]\n",
      "[0.46666667 1.         0.33333334 ... 0.         0.         0.93333334]\n",
      "[ 0.07887743 -0.04732645 -0.04732645 ... -0.07887741  0.04732646\n",
      "  0.0157755 ]\n",
      "[ 0.13122779  0.07147981  0.14192243  0.07814884 -0.39279425 -0.09664904\n",
      " -0.54337305 -0.01641652  0.08411925 -0.10248799 -0.27582037 -0.23494662\n",
      " -0.22903767  0.66736114  0.08086307  0.11460739  0.20813338  0.222242\n",
      "  0.06489582 -0.00491732 -0.00967382  0.28100353  0.21680787 -0.1023111\n",
      "  0.22088876 -0.057807   -0.14915954 -0.08736266  0.18920569 -0.1701097\n",
      "  0.25792235 -0.42285705 -0.12296606 -0.50894636 -0.1516215  -0.24492246\n",
      " -0.12235785 -0.20554557  0.0614689  -0.07543387  0.05317335 -0.05858007\n",
      "  0.01135373 -0.1431769  -0.00133289  0.09082425 -0.02147285 -0.09121155\n",
      "  0.25039703 -0.53738546  0.13363783 -0.09745693  0.46817368  0.19443604\n",
      " -0.2352869   0.25536114  0.06921577  0.03065274  0.00406705 -0.00468367\n",
      " -0.09866475  0.49028337 -0.200845   -0.02135178 -0.07119116 -0.08525351\n",
      "  0.19032246  0.36023703 -0.23567647  0.02132332 -0.38868263  0.575798\n",
      "  0.32778245 -0.16142452  0.30957168 -0.29949385  0.00551386 -0.15139955\n",
      " -0.02181493  0.25310135 -0.45776695 -0.05322464  0.21446244  0.01640192\n",
      "  0.08063167  0.1275426   0.13646477 -0.25599778 -0.2593454  -0.17496768\n",
      " -0.04886021  0.24233274  0.1545947  -0.4258439   0.10453003  0.30532998\n",
      " -0.16154367  0.00758406 -0.41546845 -0.06916269]\n"
     ]
    }
   ],
   "source": [
    "# look at some values at intermediate layer outputs\n",
    "# weights and acitvations are quantized but operations are still in full precision\n",
    "# with the final layer also full precision\n",
    "\n",
    "for output in outputs:\n",
    "    output = output.view(1, -1)\n",
    "    print(np.squeeze(output.data.numpy()[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# print outputs\n",
    "# simple loss function to look at gradients\n",
    "loss = torch.sum(out)\n",
    "print(out.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/btl787/anaconda3/lib/python3.7/site-packages/torch/quantization/quantize.py:147: UserWarning: None of the submodule got qconfig applied. Make sure you passed correct configuration through `qconfig_dict` or by assigning the `.qconfig` attribute directly on submodules\n",
      "  warnings.warn(\"None of the submodule got qconfig applied. Make sure you \"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ResNet_Cifar' object has no attribute 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4b57bdcd4b0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resnet8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_qat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ResNet_Cifar' object has no attribute 'features'"
     ]
    }
   ],
   "source": [
    "resnet = get_model('resnet8')\n",
    "torch.quantization.prepare_qat(resnet, inplace=True)\n",
    "print(resnet.features[1].conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
